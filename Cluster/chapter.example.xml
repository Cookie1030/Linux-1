<?xml version="1.0" encoding="UTF-8"?>
<!-- $Id: chapter.example.xml 374 2012-03-20 09:43:09Z netkiller $ -->
<chapter id="example">
	<title>Example</title>
	<para>这里介绍一个负载均衡放置问题，我们可以把它摆放在任何位置，每种方案都各有优缺点，需要根据你的实际情况选择使用</para>
	<para>适用于HAProxy / Nginx / LVS 等等</para>	
	<para>这里用web,db为例子，讲述负载均衡之间的关系</para>
	<section id="example1">
		<title>双负载均衡的用法</title>
		<para>User --> LB1 --> Web --> LB2 --> Database</para>
		<screen>
                 User
                  |
            LB1   V 0.0.0.0:80 
----------------------------------------
    /             |              \
web Node 1     web Node 2    web Node 3
    \             |              /        
----------------------------------------
                  |
            LB2   V 0.0.0.0:1152 / 0.0.0.0:3306
----------------------------------------
     /            |              \                      
DB Node 1     DB Node 2       DB Node 3
		</screen>
		<para>适用于所有的服务器放在一个私有局域网,防火墙将公网IP地址映射到LB1上，LB1链接web节点（使用第一块网卡），然后从第二块网卡请求数据库LB2，LB2在请求分配到数据库节点。</para>
		<para>整个案例使用了两台负载均衡设备，如果每个负载均衡都再配置一个备机。就是4台服务器，还要看你的经济情况。</para>
		<para>前面我说需要在在一个局域网中，为什么呢？因为你要考虑从用户到数据，在将结果返回的网络开销。</para>
	</section>
	<section id="example2">
		<title>单台负载均衡的用法</title>
		<para>User --> LB1(VS1,VS2) --> Web (VS1) --> Database (VS2)</para>	
		<screen>
                         User
                          |
                          V
---------------------------------------------------------------------------------------                  
                  |                        ^               |
            VS1   V 0.0.0.0:80             |         VS2   V 0.0.0.0:1152 / 0.0.0.0:3306
----------------------------------------   |   ----------------------------------------
    /             |              \         |        /            |              \     
web Node 1     web Node 2    web Node 3    |   DB Node 1     DB Node 2       DB Node 3
    \             |              /         |
----------------------------------------   |
                  |                        |
                   \_______________________.
		</screen>
		<para>使用一台服务器，通过多个虚拟服，实现多个集群分组，这个方案很好的利用服务器，管理也方便。</para>
		<para>这种方案，要注意的地方是流量开销，因为你所有的请求都需要经过同一台服务器，对它的压力很大，CPU，内存，流量等等都要做好监控手段。</para>
	</section>	
	<section id="example2">
		<title>广域网负载均衡的用法</title>
		<para>User --> Web LB1 --> Database</para>
		<screen>
                 User
                  |
            LB1   V 0.0.0.0:80 
----------------------------------------
    /             |              \
web Node 1     web Node 2    web Node 3
   LB1           LB2             LB3  
    \             |              /        
----------------------------------------
                  |
                  V 0.0.0.0:1152 / 0.0.0.0:3306
----------------------------------------
     /            |              \                      
DB Node 1     DB Node 2       DB Node 3
		</screen>
		<para>这个方案非常适合全国布点的情况，经常夸公网访问数据库等资源。我们假设所有的服务器都不在同一个机房，广域网的链接是无法保证99.9%的联通性。</para>
		<para>当一端公网的web服务器，链接另一端的数据库服务器是，一般会出现，由于网络不稳定ping时间长链接耗时严重，可能出现短时间中断，导致web不能正常工作</para>
		<para>当然你可以通过调整程序解决，当DB1链接失败后尝试链接DB2..DB3..，这样的改进仍不能满足用户需求，例如：用户链接web用了1秒中，web链接数据DB1 用了30秒发现链接不上，在去链接DB2，最终用户打开网页至少32秒,而且下一个用户也会重复这样的操作去DB1链接在到DB2</para>
		<para>你也可以考虑在增加一台负载均衡，但新的问题来了，web 到这台负载均衡的网络就能保证吗？</para>
		<para>我的解决方法是，每个web server上都安装负载均衡软件，Web与负载均衡安装在一台服务器上，用户链接到web（通过智能DNS）,web请求数据库localhost:3306负载均衡分配到数据库节点，这样可以解决当web服务器链接公网上的另一台数据服务器的时候，能保证剔除不稳定的节点，同时减少了web到另一台负载均衡设备上的开销</para>
	</section>			
</chapter>
